{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import ipython_bell\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import sys\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes 3 plots per image: source simulation, lens cutout, complete simulation\n",
    "def make_graphs(name, sim_i, sim_r, sim_g, cutout_i, cutout_r, cutout_g):\n",
    "    loc = plticker.MultipleLocator(base=3.75)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(15, 4), ncols=3)\n",
    "\n",
    "    rgb = make_lupton_rgb(sim_i, sim_r, sim_g, Q=11., stretch=40.)\n",
    "    ax1.set_title('Source(s)')\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    #ax1.xaxis.set_major_locator(loc)\n",
    "    #ax1.yaxis.set_major_locator(loc)\n",
    "    #ax1.grid(which='major', axis='both', linestyle='-')\n",
    "    original = ax1.imshow(rgb, aspect='equal')#, vmin=0, vmax = 250)\n",
    "    #fig.colorbar(original, ax=ax1)\n",
    "\n",
    "    rgb = make_lupton_rgb(cutout_i, cutout_r, cutout_g, Q=11., stretch=40.)\n",
    "    ax2.set_title('Lens')\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    ax2.yaxis.set_ticklabels([])\n",
    "    #ax2.xaxis.set_major_locator(loc)\n",
    "    #ax2.yaxis.set_major_locator(loc)\n",
    "    #ax2.grid(which='major', axis='both', linestyle='-')\n",
    "    cutout = ax2.imshow(rgb, aspect='equal')\n",
    "    #fig.colorbar(cutout, ax=ax2)\n",
    "            \n",
    "    rgb = make_lupton_rgb(sim_i+cutout_i, sim_r+cutout_r, sim_g+cutout_g, Q=11., stretch=40.)\n",
    "    ax3.set_title('Complete Simulation')\n",
    "    ax3.xaxis.set_ticklabels([])\n",
    "    ax3.yaxis.set_ticklabels([])\n",
    "    #ax3.xaxis.set_major_locator(loc)\n",
    "    #ax3.yaxis.set_major_locator(loc)\n",
    "    #ax3.grid(which='major', axis='both', linestyle='-')\n",
    "    projection = ax3.imshow(rgb, aspect='equal')\n",
    "    #fig.colorbar(projection, ax=ax3)\n",
    "    sub_path = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/'\n",
    "    #plt.savefig(sub_path + 'Data/Sim_complete/Image' + name + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes fit file\n",
    "def write_fit_file(name, x, datos):\n",
    "    primary = fits.PrimaryHDU()\n",
    "    image = fits.ImageHDU(x, name=\"IMAGE\")\n",
    "    #table = fits.TableHDU(data = datos)\n",
    "    table = fits.BinTableHDU(data = datos)\n",
    "    hdu_list = fits.HDUList([primary, image, table])\n",
    "    hdu_list.writeto('/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/' + name + '.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_simulations(m, ids):\n",
    "    directory_sim = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim/'\n",
    "    directory_cutouts = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/lens_cutouts/'\n",
    "    end_name = ['_g.fits', '_i.fits', '_r.fits']\n",
    "    x = np.zeros((1,3,46,46)) #Complete Simulations\n",
    "    n = 0\n",
    "    for lens_id in ids:\n",
    "        path_sim_id = directory_sim + str(lens_id)\n",
    "        if(n >= m):\n",
    "            break\n",
    "        #check that the sim id folder exist (if not continue)\n",
    "        if(os.path.exists(path_sim_id) == False):\n",
    "            continue\n",
    "        num_sim_id = int(len(os.listdir(path_sim_id))/3) # num sim with same lens\n",
    "        #loop on each simulation produced using the same lens\n",
    "        for j in range(1, num_sim_id+1):\n",
    "            if(n >= m):\n",
    "                break\n",
    "            n += 1 #number of total simulations\n",
    "            path_cutout = directory_cutouts + str(lens_id) \n",
    "            path_sim = path_sim_id + '/' + str(j)\n",
    "            if(os.path.exists(path_cutout + end_name[0]) == False): \n",
    "                continue\n",
    "            with fits.open(path_cutout + end_name[0]) as hdul: cutout_g = hdul[0].data\n",
    "            with fits.open(path_cutout + end_name[1]) as hdul: cutout_i = hdul[0].data\n",
    "            with fits.open(path_cutout + end_name[2]) as hdul: cutout_r = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[0]) as hdul: sim_g = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[1]) as hdul: sim_i = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[2]) as hdul: sim_r = hdul[0].data\n",
    "            \n",
    "            ele_sim = np.array([cutout_g + sim_g, cutout_r + sim_r, cutout_i + sim_i])\n",
    "            ele_sim = np.rot90(ele_sim, k=random.randint(0, 4), axes=(1, 2))\n",
    "            if(random.randint(0, 1) == 1):\n",
    "                ele_sim = np.flip(ele_sim, 2)\n",
    "            x = np.append(x, [ele_sim], axis = 0)\n",
    "    x = np.delete(x, 0, axis = 0)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "#19712 lens cutouts\n",
    "ids = pd.read_csv('/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/all_data_sim.csv')['COADD_OBJECT_ID'].sample(frac = 1)\n",
    "x = complete_simulations(202, ids)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=202</i>\n",
       "<table id=\"table140317416877008\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>a</th><th>b</th><th>c</th><th>d</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=202>\n",
       "   a       b       c       d   \n",
       "float64 float64 float64 float64\n",
       "------- ------- ------- -------\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    ...     ...     ...     ...\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating table:\n",
    "\n",
    "datos = np.zeros((1,4))\n",
    "ele_sim = np.array([1,2,3,4])\n",
    "\n",
    "for i in range(67):\n",
    "    datos = np.append(datos, np.ones((1,4)), axis = 0)\n",
    "    datos = np.append(datos, [ele_sim], axis = 0)  \n",
    "    datos = np.append(datos, np.zeros((1,4)), axis = 0)\n",
    "\n",
    "#print(datos)\n",
    "\n",
    "names = ['a', 'b', 'c', 'd']\n",
    "datos = Table(data = datos, names = names)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = 'other' #'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 3, 46, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "write_fit_file(name_file, x, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/other.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  IMAGE         1 ImageHDU        10   (46, 46, 3, 202)   float64   \n",
      "  2                1 BinTableHDU     16   202R x 4C   [D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "filename = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/'\n",
    "filename = filename + 'other.fits'\n",
    "hdul = fits.open(filename)\n",
    "hdul.info()\n",
    "images = hdul[1].data.astype(np.float32)\n",
    "datos = hdul[2].data\n",
    "hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 3, 46, 46)\n",
      "(202,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "l1, l2 = np.zeros(int(len(x)/2), dtype = np.int64), np.ones(int(len(x)/2), dtype = np.int64)\n",
    "labels = np.concatenate((l1, l2))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.)]\n",
      "(202, 4)\n"
     ]
    }
   ],
   "source": [
    "print(datos)\n",
    "df = pd.DataFrame(datos)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of Images and Labels\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Create a PyTorch dataset from an array of images\n",
    "\t\tand an array of labels\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.images[idx]\n",
    "        label = np.array(self.labels[idx])\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\t\t\n",
    "\t\t# I like to add any scaling functions here, so uncomment if desired\n",
    "\t\t#image = (image - np.min(image, axis=(-1,-2))[:,:,np.newaxis,np.newaxis]) / np.max(image - np.min(image, axis=(-1,-2))[:,:,np.newaxis,np.newaxis], axis=(-1,-2))[:,:,np.newaxis,np.newaxis]\n",
    "\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_datasets(images, data, labels, test_size=0.2, transform=ToTensor()):\n",
    "    \"\"\"\n",
    "\tMake training and testing datasets\n",
    "\t\n",
    "\tArgs:\n",
    "\t    images: 4D array of all images\n",
    "        labels: 1D array of the labels for each image\n",
    "        test_size: the fraction of the images to use as the test dataset\n",
    "\t\ttransform: the PyTorch transformation to apply to the data\n",
    "\t\t\n",
    "\tReturns\n",
    "\t    train_dataset: An instance of the ImageDataset Class for training\n",
    "\t\ttest_dataset: An instance of the ImageDataset Class for testing\n",
    "\t\"\"\"\n",
    "\n",
    "    # Shuffle and split data\n",
    "    y = labels\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=8, stratify=y)\n",
    "    \n",
    "    train_data, test_data, ttrain_labels, ttest_labels = train_test_split(\n",
    "        data, labels, test_size=test_size, random_state=8, stratify=y)\n",
    "    \n",
    "    print(train_labels)\n",
    "    print(ttrain_labels)\n",
    "    \n",
    "    # Create a PyTorch Dataset\n",
    "    return (ImageDataset(train_images, train_labels, transform=transform),\n",
    "            ImageDataset(test_images, test_labels, transform=transform), train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for multiband data. Note that you\n",
    "    will need to update the number of in_features for self.fc3.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        \"\"\"\n",
    "\t\tArgs:\n",
    "\t\t    in_channels: number of bands (gri = 3, griz=4)\n",
    "\t\t\tnum_classes: number of unique labels in your dataset\n",
    "\t\t\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #Network Components\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                               out_channels=48, \n",
    "                               kernel_size=15, \n",
    "                               stride=3,\n",
    "                               padding=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=48, \n",
    "                               out_channels=96,\n",
    "                               kernel_size=5, \n",
    "                               stride=1,\n",
    "                               padding=2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=3456, \n",
    "                             out_features=408)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=408, \n",
    "                             out_features=25)\n",
    "\n",
    "        self.fc3 = nn.Linear(in_features=25, \n",
    "                             out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Network Flow\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if (type(m) == nn.Linear or type(m) == nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(\n",
    "    cnn, \n",
    "    train_dataloader, \n",
    "    train_dataset=None,\n",
    "    test_dataset=None,\n",
    "    validation_size=None, \n",
    "    monitor=False,\n",
    "    number_of_training_epochs=10,\n",
    "    learning_rate=0.0001):\n",
    "\t\n",
    "    \"\"\"\n",
    "    Train a CNN and output performance if desired\n",
    "\n",
    "    Args:\n",
    "        cnn: an instance of the CNN class\n",
    "        train_dataloader: a PyTorch DataLoader for the training dataset\n",
    "        train_dataset: an instance of the ImageDataset class for training\n",
    "        test_dataset: an instance of the ImageDataset class for testing\n",
    "        validation_size: the number of images to use for monitoring\n",
    "            - large numbers will slow down training. ~100 is good.\n",
    "        monitor: set to True if you want status updates on training\n",
    "        number_of_training_epochs: number of times to go through the dataset\n",
    "        learning_rate: multiplicative factor for updating network weights\n",
    "            - small learning_rate will mean slow training\n",
    "            - large learning_rate will train fast, but you may miss the best weights\n",
    "            - ~0.001 is a good starting point\n",
    "    \"\"\"\n",
    "    if not monitor and (train_dataset is None or test_dataset is None):\n",
    "        raise ValueError(\"Must pass training and testing datasets for monitoring\")\n",
    "    \n",
    "    if validation_size is None:\n",
    "        validation_size=len(test_dataset)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "    \n",
    "    losses, train_acc, validation_acc = [], [], []\n",
    "\n",
    "    for epoch in range(number_of_training_epochs):\n",
    "        sys.stdout.write(\"\\rEpoch {0}\\r\".format(epoch + 1))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "\n",
    "            #Clear out all existing gradients on the loss surface to reevaluate for this step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Get the CNN's current prediction of the training data\n",
    "            output = cnn(sample_batched['image'])\n",
    "\n",
    "            #Calculate the loss by comparing the prediction to the truth\n",
    "            loss = loss_function(output, sample_batched['label']) \n",
    "\n",
    "            #Evaluate all gradients along the loss surface using back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Based on the gradients, take the optimal step in the weight space\n",
    "            optimizer.step()\n",
    "\n",
    "            #Performance monitoring if desired\n",
    "            if monitor:\n",
    "                if i_batch % 200 == 0: #before batch 200\n",
    "                    train_output = cnn(train_dataset[0:validation_size]['image'])\n",
    "                    validation_output = cnn(test_dataset[0:validation_size]['image'])\n",
    "\n",
    "                    train_predictions = torch.max(train_output, 1)[1].data.numpy()\n",
    "                    validation_predictions = torch.max(validation_output, 1)[1].data.numpy()\n",
    "\n",
    "                    train_accuracy = np.sum(train_predictions == train_dataset[0:validation_size]['label'].numpy()) / validation_size\n",
    "                    validation_accuracy = np.sum(validation_predictions == test_dataset[0:validation_size]['label'].numpy()) / validation_size\n",
    "\n",
    "                    print(\"Epoch: {0} Batch: {1}  | Training Accuracy: {2:.3f} -- Validation Accuracy: {3:.3f} -- Loss: {4:.3f}\".format(epoch + 1, i_batch + 1, train_accuracy, validation_accuracy, loss.data.numpy()))\n",
    "\n",
    "                    losses.append(loss.data.numpy())\n",
    "                    train_acc.append(train_accuracy)\n",
    "                    validation_acc.append(validation_accuracy)\n",
    "   \n",
    "    setattr(cnn, 'losses', losses)\n",
    "    setattr(cnn, 'train_acc', train_acc)\n",
    "    setattr(cnn, 'validation_acc', validation_acc)\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues, name = 'generic'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,3), dpi=120)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(classes, fontsize=12)\n",
    "    ax.set_yticklabels(classes, fontsize=12)\n",
    "    ax.set_xlabel('Predicted Class', fontsize=14)\n",
    "    ax.set_ylabel('True Class', fontsize=14)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(cnn):\n",
    "    x = np.linspace(1,len(cnn.losses),len(cnn.losses))\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7), ncols=1)\n",
    "    ax1.set_title('Performance')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.plot(x, cnn.losses, 'wo', label = 'Loss')\n",
    "    ax1.plot(x, cnn.train_acc, 'ro', label = 'Training Accuracy')\n",
    "    ax1.plot(x, cnn.validation_acc, 'go', label = 'Validation Accuracy')\n",
    "    ax1.legend()\n",
    "    plt.xlim([1.5, len(cnn.losses) + 0.5])\n",
    "    plt.ylim([0, 2])\n",
    "    plt.show(block=True)#'Performance_' + name +'.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 3, 46, 46) (202,)\n",
      "[0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
      " 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 1 1 1 1]\n",
      "[0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
      " 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 1 1 1 1]\n",
      "[1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, datos.shape)\n",
    "train_dataset, test_dataset, train_data, test_data = make_train_test_datasets(images, datos, labels)\n",
    "\n",
    "print(test_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b    c    d\n",
       "0   1.0  1.0  1.0  1.0\n",
       "1   0.0  0.0  0.0  0.0\n",
       "2   1.0  1.0  1.0  1.0\n",
       "3   0.0  0.0  0.0  0.0\n",
       "4   1.0  2.0  3.0  4.0\n",
       "5   1.0  1.0  1.0  1.0\n",
       "6   0.0  0.0  0.0  0.0\n",
       "7   1.0  1.0  1.0  1.0\n",
       "8   0.0  0.0  0.0  0.0\n",
       "9   0.0  0.0  0.0  0.0\n",
       "10  1.0  2.0  3.0  4.0\n",
       "11  1.0  2.0  3.0  4.0\n",
       "12  1.0  1.0  1.0  1.0\n",
       "13  1.0  1.0  1.0  1.0\n",
       "14  1.0  2.0  3.0  4.0\n",
       "15  1.0  2.0  3.0  4.0\n",
       "16  0.0  0.0  0.0  0.0\n",
       "17  1.0  2.0  3.0  4.0\n",
       "18  0.0  0.0  0.0  0.0\n",
       "19  0.0  0.0  0.0  0.0\n",
       "20  1.0  1.0  1.0  1.0\n",
       "21  1.0  2.0  3.0  4.0\n",
       "22  1.0  1.0  1.0  1.0\n",
       "23  1.0  2.0  3.0  4.0\n",
       "24  1.0  1.0  1.0  1.0\n",
       "25  0.0  0.0  0.0  0.0\n",
       "26  1.0  2.0  3.0  4.0\n",
       "27  0.0  0.0  0.0  0.0\n",
       "28  0.0  0.0  0.0  0.0\n",
       "29  0.0  0.0  0.0  0.0\n",
       "30  1.0  2.0  3.0  4.0\n",
       "31  0.0  0.0  0.0  0.0\n",
       "32  1.0  2.0  3.0  4.0\n",
       "33  0.0  0.0  0.0  0.0\n",
       "34  1.0  1.0  1.0  1.0\n",
       "35  0.0  0.0  0.0  0.0\n",
       "36  1.0  2.0  3.0  4.0\n",
       "37  1.0  1.0  1.0  1.0\n",
       "38  0.0  0.0  0.0  0.0\n",
       "39  0.0  0.0  0.0  0.0\n",
       "40  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 48, kernel_size=(15, 15), stride=(3, 3), padding=(2, 2))\n",
       "  (conv2): Conv2d(48, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=3456, out_features=408, bias=True)\n",
       "  (fc2): Linear(in_features=408, out_features=25, bias=True)\n",
       "  (fc3): Linear(in_features=25, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataLoader to train the network\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=4) # batch_size = 20\n",
    "\n",
    "# Make a CNN\n",
    "cnn = CNN(\n",
    "\tin_channels=np.shape(images)[1], \n",
    "\tnum_classes=len(np.unique(labels)))\n",
    "\n",
    "#Initialize weights\n",
    "cnn.apply(cnn.init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1  | Training Accuracy: 0.395 -- Validation Accuracy: 0.105 -- Loss: 19.455\n",
      "Epoch: 2 Batch: 1  | Training Accuracy: 0.430 -- Validation Accuracy: 0.105 -- Loss: 4.477\n",
      "Epoch: 3 Batch: 1  | Training Accuracy: 0.425 -- Validation Accuracy: 0.110 -- Loss: 4.767\n",
      "Epoch: 4 Batch: 1  | Training Accuracy: 0.430 -- Validation Accuracy: 0.110 -- Loss: 4.032\n",
      "Epoch: 5 Batch: 1  | Training Accuracy: 0.465 -- Validation Accuracy: 0.100 -- Loss: 3.163\n",
      "Epoch: 6 Batch: 1  | Training Accuracy: 0.380 -- Validation Accuracy: 0.095 -- Loss: 5.449\n",
      "Epoch: 7 Batch: 1  | Training Accuracy: 0.410 -- Validation Accuracy: 0.085 -- Loss: 3.142\n",
      "Epoch: 8 Batch: 1  | Training Accuracy: 0.430 -- Validation Accuracy: 0.070 -- Loss: 3.924\n",
      "Epoch: 9 Batch: 1  | Training Accuracy: 0.440 -- Validation Accuracy: 0.085 -- Loss: 3.490\n",
      "Epoch: 10 Batch: 1  | Training Accuracy: 0.460 -- Validation Accuracy: 0.075 -- Loss: 1.642\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "cnn = train_cnn(cnn, \n",
    "\t\t\t\ttrain_dataloader, \n",
    "\t\t\t\ttrain_dataset=train_dataset,\n",
    "\t\t\t\ttest_dataset=test_dataset,\n",
    "\t\t\t\tvalidation_size=200, #100\n",
    "\t\t\t\tnumber_of_training_epochs=10, #150\n",
    "\t\t\t\tmonitor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CNN to classify your whole test dataset\n",
    "cnn.eval()\n",
    "\n",
    "non_binary_predictions = cnn(test_dataset[:]['image'])\n",
    "\n",
    "test_predictions = torch.max(cnn(test_dataset[:]['image']), 1)[1].data.numpy()  \n",
    "test_labels = test_dataset[:]['label'].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0]\n",
      "[1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 1 1 0 1]\n",
      "(41, 3, 46, 46)\n",
      "      a    b    c    d\n",
      "0   1.0  1.0  1.0  1.0\n",
      "1   0.0  0.0  0.0  0.0\n",
      "2   1.0  1.0  1.0  1.0\n",
      "3   0.0  0.0  0.0  0.0\n",
      "4   1.0  2.0  3.0  4.0\n",
      "5   1.0  1.0  1.0  1.0\n",
      "6   0.0  0.0  0.0  0.0\n",
      "7   1.0  1.0  1.0  1.0\n",
      "8   0.0  0.0  0.0  0.0\n",
      "9   0.0  0.0  0.0  0.0\n",
      "10  1.0  2.0  3.0  4.0\n",
      "11  1.0  2.0  3.0  4.0\n",
      "12  1.0  1.0  1.0  1.0\n",
      "13  1.0  1.0  1.0  1.0\n",
      "14  1.0  2.0  3.0  4.0\n",
      "15  1.0  2.0  3.0  4.0\n",
      "16  0.0  0.0  0.0  0.0\n",
      "17  1.0  2.0  3.0  4.0\n",
      "18  0.0  0.0  0.0  0.0\n",
      "19  0.0  0.0  0.0  0.0\n",
      "20  1.0  1.0  1.0  1.0\n",
      "21  1.0  2.0  3.0  4.0\n",
      "22  1.0  1.0  1.0  1.0\n",
      "23  1.0  2.0  3.0  4.0\n",
      "24  1.0  1.0  1.0  1.0\n",
      "25  0.0  0.0  0.0  0.0\n",
      "26  1.0  2.0  3.0  4.0\n",
      "27  0.0  0.0  0.0  0.0\n",
      "28  0.0  0.0  0.0  0.0\n",
      "29  0.0  0.0  0.0  0.0\n",
      "30  1.0  2.0  3.0  4.0\n",
      "31  0.0  0.0  0.0  0.0\n",
      "32  1.0  2.0  3.0  4.0\n",
      "33  0.0  0.0  0.0  0.0\n",
      "34  1.0  1.0  1.0  1.0\n",
      "35  0.0  0.0  0.0  0.0\n",
      "36  1.0  2.0  3.0  4.0\n",
      "37  1.0  1.0  1.0  1.0\n",
      "38  0.0  0.0  0.0  0.0\n",
      "39  0.0  0.0  0.0  0.0\n",
      "40  0.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# I have test_predictions, test_labels, test_dataset and test_data (df)\n",
    "print(test_predictions)\n",
    "print(test_labels)\n",
    "print(test_dataset.images.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indices of test dataset where the label is wrong predicted\n",
    "indices = []\n",
    "for i in range(len(test_labels)):\n",
    "    if(test_predictions[i] != test_labels[i]):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 17, 18, 21, 27, 29, 30, 34, 35, 36, 38, 40]\n"
     ]
    }
   ],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FITS_rec([(1., 1., 1., 1.), (0., 0., 0., 0.), (1., 1., 1., 1.),\n",
       "          (0., 0., 0., 0.), (1., 2., 3., 4.), (0., 0., 0., 0.),\n",
       "          (1., 1., 1., 1.), (0., 0., 0., 0.), (1., 2., 3., 4.),\n",
       "          (1., 1., 1., 1.), (1., 2., 3., 4.), (1., 2., 3., 4.),\n",
       "          (0., 0., 0., 0.), (1., 2., 3., 4.), (0., 0., 0., 0.),\n",
       "          (0., 0., 0., 0.), (1., 2., 3., 4.), (1., 1., 1., 1.),\n",
       "          (0., 0., 0., 0.), (1., 2., 3., 4.), (0., 0., 0., 0.),\n",
       "          (0., 0., 0., 0.)],\n",
       "         dtype=(numpy.record, [('a', '>f8'), ('b', '>f8'), ('c', '>f8'), ('d', '>f8')]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b    c    d\n",
       "0   1.0  1.0  1.0  1.0\n",
       "1   0.0  0.0  0.0  0.0\n",
       "2   1.0  1.0  1.0  1.0\n",
       "3   0.0  0.0  0.0  0.0\n",
       "4   1.0  2.0  3.0  4.0\n",
       "5   1.0  1.0  1.0  1.0\n",
       "6   0.0  0.0  0.0  0.0\n",
       "7   1.0  1.0  1.0  1.0\n",
       "8   0.0  0.0  0.0  0.0\n",
       "9   0.0  0.0  0.0  0.0\n",
       "10  1.0  2.0  3.0  4.0\n",
       "11  1.0  2.0  3.0  4.0\n",
       "12  1.0  1.0  1.0  1.0\n",
       "13  1.0  1.0  1.0  1.0\n",
       "14  1.0  2.0  3.0  4.0\n",
       "15  1.0  2.0  3.0  4.0\n",
       "16  0.0  0.0  0.0  0.0\n",
       "17  1.0  2.0  3.0  4.0\n",
       "18  0.0  0.0  0.0  0.0\n",
       "19  0.0  0.0  0.0  0.0\n",
       "20  1.0  1.0  1.0  1.0\n",
       "21  1.0  2.0  3.0  4.0\n",
       "22  1.0  1.0  1.0  1.0\n",
       "23  1.0  2.0  3.0  4.0\n",
       "24  1.0  1.0  1.0  1.0\n",
       "25  0.0  0.0  0.0  0.0\n",
       "26  1.0  2.0  3.0  4.0\n",
       "27  0.0  0.0  0.0  0.0\n",
       "28  0.0  0.0  0.0  0.0\n",
       "29  0.0  0.0  0.0  0.0\n",
       "30  1.0  2.0  3.0  4.0\n",
       "31  0.0  0.0  0.0  0.0\n",
       "32  1.0  2.0  3.0  4.0\n",
       "33  0.0  0.0  0.0  0.0\n",
       "34  1.0  1.0  1.0  1.0\n",
       "35  0.0  0.0  0.0  0.0\n",
       "36  1.0  2.0  3.0  4.0\n",
       "37  1.0  1.0  1.0  1.0\n",
       "38  0.0  0.0  0.0  0.0\n",
       "39  0.0  0.0  0.0  0.0\n",
       "40  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    1.0\n",
       "c    1.0\n",
       "d    1.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, : ]\n",
    "#df.iloc[['1', '0'], : ]\n",
    "#dfObj.iloc[[2 ,0 ] , : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wpredic = test_data[indices] #sample in test wrong predicted\n",
    "wpredic['a']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(wpredic['a'], 3)\n",
    "plt.show()\n",
    "#incluso puedo hacer una grafica de prediccion no binaria vs valor parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71310806 0.09422374 0.5125792  0.5176673  0.48011842 0.53920424\n",
      " 0.75553733 0.62694067 0.7660998  0.4597451  0.6020204  0.06431361\n",
      " 0.72693837 0.56002426 0.55130684 0.64675933 0.60977316 0.45543832\n",
      " 0.49453038 0.521461   0.5453838  0.4949685  0.6286184  0.6508484\n",
      " 0.4410556  0.54774624 0.5108703  0.4654329  0.4998653  0.5425206\n",
      " 0.48711157 0.5842826  0.1419606  0.62752414 0.7988455  0.51889765\n",
      " 0.5805328  0.4324627  0.53300667 0.74872106 0.9941308 ]\n",
      "[0.28689197 0.90577626 0.48742074 0.4823327  0.5198816  0.46079576\n",
      " 0.24446265 0.37305936 0.23390025 0.5402549  0.39797962 0.93568635\n",
      " 0.2730616  0.43997574 0.4486932  0.35324073 0.39022684 0.5445617\n",
      " 0.50546956 0.47853902 0.45461625 0.5050315  0.37138158 0.34915155\n",
      " 0.5589444  0.4522538  0.48912975 0.5345671  0.5001347  0.4574794\n",
      " 0.5128885  0.41571742 0.8580394  0.37247586 0.20115454 0.48110235\n",
      " 0.41946718 0.5675373  0.46699336 0.25127888 0.00586914]\n",
      "[1.         1.         0.99999994 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99999994\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99999994 1.         1.         1.         1.         0.99999994\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.0000001  1.\n",
      " 1.         1.         1.         0.99999994 0.99999994]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_binary_predictions = cnn(test_dataset[:]['image'])\n",
    "m = nn.Softmax(dim=1) \n",
    "prob = (m(non_binary_predictions))\n",
    "print(prob[:,0].detach().numpy())\n",
    "print(prob[:,1].detach().numpy())\n",
    "print(prob[:,1].detach().numpy() + prob[:,0].detach().numpy())\n",
    "prob = prob[:,0].detach().numpy()\n",
    "#print(prob)\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(prob, 100, color = \"skyblue\", label = 'prob 0')\n",
    "#plt.hist(y, 100, color = \"pink\", label = '1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(prob[indices], wpredic['a'], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
