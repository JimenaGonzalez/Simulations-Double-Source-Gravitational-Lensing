{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import ipython_bell\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import sys\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes 3 plots per image: source simulation, lens cutout, complete simulation\n",
    "def make_graphs(name, sim_i, sim_r, sim_g, cutout_i, cutout_r, cutout_g):\n",
    "    loc = plticker.MultipleLocator(base=3.75)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(15, 4), ncols=3)\n",
    "\n",
    "    rgb = make_lupton_rgb(sim_i, sim_r, sim_g, Q=11., stretch=40.)\n",
    "    ax1.set_title('Source(s)')\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    #ax1.xaxis.set_major_locator(loc)\n",
    "    #ax1.yaxis.set_major_locator(loc)\n",
    "    #ax1.grid(which='major', axis='both', linestyle='-')\n",
    "    original = ax1.imshow(rgb, aspect='equal')#, vmin=0, vmax = 250)\n",
    "    #fig.colorbar(original, ax=ax1)\n",
    "\n",
    "    rgb = make_lupton_rgb(cutout_i, cutout_r, cutout_g, Q=11., stretch=40.)\n",
    "    ax2.set_title('Lens')\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    ax2.yaxis.set_ticklabels([])\n",
    "    #ax2.xaxis.set_major_locator(loc)\n",
    "    #ax2.yaxis.set_major_locator(loc)\n",
    "    #ax2.grid(which='major', axis='both', linestyle='-')\n",
    "    cutout = ax2.imshow(rgb, aspect='equal')\n",
    "    #fig.colorbar(cutout, ax=ax2)\n",
    "            \n",
    "    rgb = make_lupton_rgb(sim_i+cutout_i, sim_r+cutout_r, sim_g+cutout_g, Q=11., stretch=40.)\n",
    "    ax3.set_title('Complete Simulation')\n",
    "    ax3.xaxis.set_ticklabels([])\n",
    "    ax3.yaxis.set_ticklabels([])\n",
    "    #ax3.xaxis.set_major_locator(loc)\n",
    "    #ax3.yaxis.set_major_locator(loc)\n",
    "    #ax3.grid(which='major', axis='both', linestyle='-')\n",
    "    projection = ax3.imshow(rgb, aspect='equal')\n",
    "    #fig.colorbar(projection, ax=ax3)\n",
    "    sub_path = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/'\n",
    "    #plt.savefig(sub_path + 'Data/Sim_complete/Image' + name + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes fit file\n",
    "def write_fit_file(name, x, datos):\n",
    "    primary = fits.PrimaryHDU()\n",
    "    image = fits.ImageHDU(x, name=\"IMAGE\")\n",
    "    #table = fits.TableHDU(data = datos)\n",
    "    table = fits.BinTableHDU(data = datos)\n",
    "    hdu_list = fits.HDUList([primary, image, table])\n",
    "    hdu_list.writeto('/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/' + name + '.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_simulations(m, ids):\n",
    "    directory_sim = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim/'\n",
    "    directory_cutouts = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/lens_cutouts/'\n",
    "    end_name = ['_g.fits', '_i.fits', '_r.fits']\n",
    "    x = np.zeros((1,3,46,46)) #Complete Simulations\n",
    "    n = 0\n",
    "    for lens_id in ids:\n",
    "        path_sim_id = directory_sim + str(lens_id)\n",
    "        if(n >= m):\n",
    "            break\n",
    "        #check that the sim id folder exist (if not continue)\n",
    "        if(os.path.exists(path_sim_id) == False):\n",
    "            continue\n",
    "        num_sim_id = int(len(os.listdir(path_sim_id))/3) # num sim with same lens\n",
    "        #loop on each simulation produced using the same lens\n",
    "        for j in range(1, num_sim_id+1):\n",
    "            if(n >= m):\n",
    "                break\n",
    "            n += 1 #number of total simulations\n",
    "            path_cutout = directory_cutouts + str(lens_id) \n",
    "            path_sim = path_sim_id + '/' + str(j)\n",
    "            if(os.path.exists(path_cutout + end_name[0]) == False): \n",
    "                continue\n",
    "            with fits.open(path_cutout + end_name[0]) as hdul: cutout_g = hdul[0].data\n",
    "            with fits.open(path_cutout + end_name[1]) as hdul: cutout_i = hdul[0].data\n",
    "            with fits.open(path_cutout + end_name[2]) as hdul: cutout_r = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[0]) as hdul: sim_g = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[1]) as hdul: sim_i = hdul[0].data\n",
    "            with fits.open(path_sim + end_name[2]) as hdul: sim_r = hdul[0].data\n",
    "            \n",
    "            ele_sim = np.array([cutout_g + sim_g, cutout_r + sim_r, cutout_i + sim_i])\n",
    "            ele_sim = np.rot90(ele_sim, k=random.randint(0, 4), axes=(1, 2))\n",
    "            if(random.randint(0, 1) == 1):\n",
    "                ele_sim = np.flip(ele_sim, 2)\n",
    "            x = np.append(x, [ele_sim], axis = 0)\n",
    "    x = np.delete(x, 0, axis = 0)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "#19712 lens cutouts\n",
    "ids = pd.read_csv('/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/all_data_sim.csv')['COADD_OBJECT_ID'].sample(frac = 1)\n",
    "x = complete_simulations(34, ids)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=34</i>\n",
       "<table id=\"table140286368916368\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>a</th><th>b</th><th>c</th><th>d</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>1.0</td><td>2.0</td><td>3.0</td><td>4.0</td></tr>\n",
       "<tr><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=34>\n",
       "   a       b       c       d   \n",
       "float64 float64 float64 float64\n",
       "------- ------- ------- -------\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    ...     ...     ...     ...\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0\n",
       "    1.0     1.0     1.0     1.0\n",
       "    1.0     2.0     3.0     4.0\n",
       "    0.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating table:\n",
    "\n",
    "datos = np.zeros((1,4))\n",
    "ele_sim = np.array([1,2,3,4])\n",
    "\n",
    "for i in range(11):\n",
    "    datos = np.append(datos, np.ones((1,4)), axis = 0)\n",
    "    datos = np.append(datos, [ele_sim], axis = 0)  \n",
    "    datos = np.append(datos, np.zeros((1,4)), axis = 0)\n",
    "\n",
    "#print(datos)\n",
    "\n",
    "names = ['a', 'b', 'c', 'd']\n",
    "datos = Table(data = datos, names = names)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = 'other' #'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 3, 46, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "write_fit_file(name_file, x, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/other.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  IMAGE         1 ImageHDU        10   (46, 46, 3, 34)   float64   \n",
      "  2                1 BinTableHDU     16   34R x 4C   [D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "filename = '/Users/jimenagonzalez/research/DSPL/Simulations-Double-Source-Gravitational-Lensing/Data/Sim_complete/'\n",
    "filename = filename + 'other.fits'\n",
    "hdul = fits.open(filename)\n",
    "hdul.info()\n",
    "images = hdul[1].data.astype(np.float32)\n",
    "datos = hdul[2].data\n",
    "hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 3, 46, 46)\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "l1, l2 = np.zeros(int(len(x)/2), dtype = np.int64), np.ones(int(len(x)/2), dtype = np.int64)\n",
    "labels = np.concatenate((l1, l2))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.)\n",
      " (0., 0., 0., 0.) (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.)\n",
      " (1., 1., 1., 1.) (1., 2., 3., 4.) (0., 0., 0., 0.) (1., 1., 1., 1.)\n",
      " (1., 2., 3., 4.) (0., 0., 0., 0.)]\n",
      "(34, 4)\n"
     ]
    }
   ],
   "source": [
    "print(datos)\n",
    "df = pd.DataFrame(datos)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of Images and Labels\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Create a PyTorch dataset from an array of images\n",
    "\t\tand an array of labels\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.images[idx]\n",
    "        label = np.array(self.labels[idx])\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\t\t\n",
    "\t\t# I like to add any scaling functions here, so uncomment if desired\n",
    "\t\t#image = (image - np.min(image, axis=(-1,-2))[:,:,np.newaxis,np.newaxis]) / np.max(image - np.min(image, axis=(-1,-2))[:,:,np.newaxis,np.newaxis], axis=(-1,-2))[:,:,np.newaxis,np.newaxis]\n",
    "\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_datasets(images, data, labels, test_size=0.2, transform=ToTensor()):\n",
    "    \"\"\"\n",
    "\tMake training and testing datasets\n",
    "\t\n",
    "\tArgs:\n",
    "\t    images: 4D array of all images\n",
    "        labels: 1D array of the labels for each image\n",
    "        test_size: the fraction of the images to use as the test dataset\n",
    "\t\ttransform: the PyTorch transformation to apply to the data\n",
    "\t\t\n",
    "\tReturns\n",
    "\t    train_dataset: An instance of the ImageDataset Class for training\n",
    "\t\ttest_dataset: An instance of the ImageDataset Class for testing\n",
    "\t\"\"\"\n",
    "\n",
    "    # Shuffle and split data\n",
    "    y = labels\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=8, stratify=y)\n",
    "    \n",
    "    train_data, test_data, ttrain_labels, ttest_labels = train_test_split(\n",
    "        data, labels, test_size=test_size, random_state=8, stratify=y)\n",
    "    \n",
    "    print(train_labels)\n",
    "    print(ttrain_labels)\n",
    "    \n",
    "    # Create a PyTorch Dataset\n",
    "    return (ImageDataset(train_images, train_labels, transform=transform),\n",
    "            ImageDataset(test_images, test_labels, transform=transform), train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for multiband data. Note that you\n",
    "    will need to update the number of in_features for self.fc3.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        \"\"\"\n",
    "\t\tArgs:\n",
    "\t\t    in_channels: number of bands (gri = 3, griz=4)\n",
    "\t\t\tnum_classes: number of unique labels in your dataset\n",
    "\t\t\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #Network Components\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                               out_channels=48, \n",
    "                               kernel_size=15, \n",
    "                               stride=3,\n",
    "                               padding=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=48, \n",
    "                               out_channels=96,\n",
    "                               kernel_size=5, \n",
    "                               stride=1,\n",
    "                               padding=2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=3456, \n",
    "                             out_features=408)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=408, \n",
    "                             out_features=25)\n",
    "\n",
    "        self.fc3 = nn.Linear(in_features=25, \n",
    "                             out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Network Flow\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if (type(m) == nn.Linear or type(m) == nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(\n",
    "    cnn, \n",
    "    train_dataloader, \n",
    "    train_dataset=None,\n",
    "    test_dataset=None,\n",
    "    validation_size=None, \n",
    "    monitor=False,\n",
    "    number_of_training_epochs=10,\n",
    "    learning_rate=0.0001):\n",
    "\t\n",
    "    \"\"\"\n",
    "    Train a CNN and output performance if desired\n",
    "\n",
    "    Args:\n",
    "        cnn: an instance of the CNN class\n",
    "        train_dataloader: a PyTorch DataLoader for the training dataset\n",
    "        train_dataset: an instance of the ImageDataset class for training\n",
    "        test_dataset: an instance of the ImageDataset class for testing\n",
    "        validation_size: the number of images to use for monitoring\n",
    "            - large numbers will slow down training. ~100 is good.\n",
    "        monitor: set to True if you want status updates on training\n",
    "        number_of_training_epochs: number of times to go through the dataset\n",
    "        learning_rate: multiplicative factor for updating network weights\n",
    "            - small learning_rate will mean slow training\n",
    "            - large learning_rate will train fast, but you may miss the best weights\n",
    "            - ~0.001 is a good starting point\n",
    "    \"\"\"\n",
    "    if not monitor and (train_dataset is None or test_dataset is None):\n",
    "        raise ValueError(\"Must pass training and testing datasets for monitoring\")\n",
    "    \n",
    "    if validation_size is None:\n",
    "        validation_size=len(test_dataset)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "    \n",
    "    losses, train_acc, validation_acc = [], [], []\n",
    "\n",
    "    for epoch in range(number_of_training_epochs):\n",
    "        sys.stdout.write(\"\\rEpoch {0}\\r\".format(epoch + 1))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "\n",
    "            #Clear out all existing gradients on the loss surface to reevaluate for this step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Get the CNN's current prediction of the training data\n",
    "            output = cnn(sample_batched['image'])\n",
    "\n",
    "            #Calculate the loss by comparing the prediction to the truth\n",
    "            loss = loss_function(output, sample_batched['label']) \n",
    "\n",
    "            #Evaluate all gradients along the loss surface using back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Based on the gradients, take the optimal step in the weight space\n",
    "            optimizer.step()\n",
    "\n",
    "            #Performance monitoring if desired\n",
    "            if monitor:\n",
    "                if i_batch % 200 == 0: #before batch 200\n",
    "                    train_output = cnn(train_dataset[0:validation_size]['image'])\n",
    "                    validation_output = cnn(test_dataset[0:validation_size]['image'])\n",
    "\n",
    "                    train_predictions = torch.max(train_output, 1)[1].data.numpy()\n",
    "                    validation_predictions = torch.max(validation_output, 1)[1].data.numpy()\n",
    "\n",
    "                    train_accuracy = np.sum(train_predictions == train_dataset[0:validation_size]['label'].numpy()) / validation_size\n",
    "                    validation_accuracy = np.sum(validation_predictions == test_dataset[0:validation_size]['label'].numpy()) / validation_size\n",
    "\n",
    "                    print(\"Epoch: {0} Batch: {1}  | Training Accuracy: {2:.3f} -- Validation Accuracy: {3:.3f} -- Loss: {4:.3f}\".format(epoch + 1, i_batch + 1, train_accuracy, validation_accuracy, loss.data.numpy()))\n",
    "\n",
    "                    losses.append(loss.data.numpy())\n",
    "                    train_acc.append(train_accuracy)\n",
    "                    validation_acc.append(validation_accuracy)\n",
    "   \n",
    "    setattr(cnn, 'losses', losses)\n",
    "    setattr(cnn, 'train_acc', train_acc)\n",
    "    setattr(cnn, 'validation_acc', validation_acc)\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues, name = 'generic'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,3), dpi=120)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(classes, fontsize=12)\n",
    "    ax.set_yticklabels(classes, fontsize=12)\n",
    "    ax.set_xlabel('Predicted Class', fontsize=14)\n",
    "    ax.set_ylabel('True Class', fontsize=14)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(cnn):\n",
    "    x = np.linspace(1,len(cnn.losses),len(cnn.losses))\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7), ncols=1)\n",
    "    ax1.set_title('Performance')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.plot(x, cnn.losses, 'wo', label = 'Loss')\n",
    "    ax1.plot(x, cnn.train_acc, 'ro', label = 'Training Accuracy')\n",
    "    ax1.plot(x, cnn.validation_acc, 'go', label = 'Validation Accuracy')\n",
    "    ax1.legend()\n",
    "    plt.xlim([1.5, len(cnn.losses) + 0.5])\n",
    "    plt.ylim([0, 2])\n",
    "    plt.show(block=True)#'Performance_' + name +'.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 3, 46, 46) (34,)\n",
      "[1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      "[1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      "[0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, datos.shape)\n",
    "train_dataset, test_dataset, train_data, test_data = make_train_test_datasets(images, datos, labels)\n",
    "\n",
    "print(test_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d\n",
       "0  1.0  2.0  3.0  4.0\n",
       "1  1.0  1.0  1.0  1.0\n",
       "2  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0\n",
       "4  1.0  2.0  3.0  4.0\n",
       "5  1.0  1.0  1.0  1.0\n",
       "6  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 48, kernel_size=(15, 15), stride=(3, 3), padding=(2, 2))\n",
       "  (conv2): Conv2d(48, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=3456, out_features=408, bias=True)\n",
       "  (fc2): Linear(in_features=408, out_features=25, bias=True)\n",
       "  (fc3): Linear(in_features=25, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataLoader to train the network\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=4) # batch_size = 20\n",
    "\n",
    "# Make a CNN\n",
    "cnn = CNN(\n",
    "\tin_channels=np.shape(images)[1], \n",
    "\tnum_classes=len(np.unique(labels)))\n",
    "\n",
    "#Initialize weights\n",
    "cnn.apply(cnn.init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1  | Training Accuracy: 0.060 -- Validation Accuracy: 0.020 -- Loss: 8.895\n",
      "Epoch: 2 Batch: 1  | Training Accuracy: 0.080 -- Validation Accuracy: 0.020 -- Loss: 7.963\n",
      "Epoch: 3 Batch: 1  | Training Accuracy: 0.070 -- Validation Accuracy: 0.010 -- Loss: 5.447\n",
      "Epoch: 4 Batch: 1  | Training Accuracy: 0.060 -- Validation Accuracy: 0.015 -- Loss: 0.373\n",
      "Epoch: 5 Batch: 1  | Training Accuracy: 0.065 -- Validation Accuracy: 0.015 -- Loss: 8.053\n",
      "Epoch: 6 Batch: 1  | Training Accuracy: 0.080 -- Validation Accuracy: 0.010 -- Loss: 6.574\n",
      "Epoch: 7 Batch: 1  | Training Accuracy: 0.085 -- Validation Accuracy: 0.015 -- Loss: 2.819\n",
      "Epoch: 8 Batch: 1  | Training Accuracy: 0.055 -- Validation Accuracy: 0.015 -- Loss: 4.773\n",
      "Epoch: 9 Batch: 1  | Training Accuracy: 0.065 -- Validation Accuracy: 0.030 -- Loss: 7.624\n",
      "Epoch: 10 Batch: 1  | Training Accuracy: 0.060 -- Validation Accuracy: 0.020 -- Loss: 2.769\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "cnn = train_cnn(cnn, \n",
    "\t\t\t\ttrain_dataloader, \n",
    "\t\t\t\ttrain_dataset=train_dataset,\n",
    "\t\t\t\ttest_dataset=test_dataset,\n",
    "\t\t\t\tvalidation_size=200, #100\n",
    "\t\t\t\tnumber_of_training_epochs=10, #150\n",
    "\t\t\t\tmonitor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CNN to classify your whole test dataset\n",
    "cnn.eval()\n",
    "\n",
    "non_binary_predictions = cnn(test_dataset[:]['image'])\n",
    "\n",
    "test_predictions = torch.max(cnn(test_dataset[:]['image']), 1)[1].data.numpy()  \n",
    "test_labels = test_dataset[:]['label'].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 1]\n",
      "[0 0 1 0 1 1 1]\n",
      "(7, 3, 46, 46)\n",
      "     a    b    c    d\n",
      "0  1.0  2.0  3.0  4.0\n",
      "1  1.0  1.0  1.0  1.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  0.0  0.0  0.0  0.0\n",
      "4  1.0  2.0  3.0  4.0\n",
      "5  1.0  1.0  1.0  1.0\n",
      "6  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# I have test_predictions, test_labels, test_dataset and test_data (df)\n",
    "print(test_predictions)\n",
    "print(test_labels)\n",
    "print(test_dataset.images.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indices of test dataset where the label is wrong predicted\n",
    "indices = []\n",
    "for i in range(len(test_labels)):\n",
    "    if(test_predictions[i] != test_labels[i]):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FITS_rec([(0., 0., 0., 0.), (0., 0., 0., 0.), (1., 2., 3., 4.)],\n",
       "         dtype=(numpy.record, [('a', '>f8'), ('b', '>f8'), ('c', '>f8'), ('d', '>f8')]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d\n",
       "0  1.0  2.0  3.0  4.0\n",
       "1  1.0  1.0  1.0  1.0\n",
       "2  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0\n",
       "4  1.0  2.0  3.0  4.0\n",
       "5  1.0  1.0  1.0  1.0\n",
       "6  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "d    4.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, : ]\n",
    "#df.iloc[['1', '0'], : ]\n",
    "#dfObj.iloc[[2 ,0 ] , : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wpredic = test_data[indices]\n",
    "wpredic['a']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(wpredic['a'], 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
